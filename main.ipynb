{"cells":[{"cell_type":"markdown","source":["Link to the Weights & Biases report vizualizing the training: https://api.wandb.ai/links/jacspa/k45ni2lb"],"metadata":{"id":"ciIIp5TJ4XYt"}},{"cell_type":"markdown","metadata":{"id":"u1BjKG4TCIvW"},"source":["### Environment preparation"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24233,"status":"ok","timestamp":1684935597021,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"},"user_tz":-120},"id":"cOn7Kik5IcZw","outputId":"51247c7e-5376-4235-a8a2-6c66ed1e9e11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"X5c6u0PRIdxv","executionInfo":{"status":"ok","timestamp":1684935599498,"user_tz":-120,"elapsed":425,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"outputs":[],"source":["# Define constants used in the whole notebook\n","PATH = \"/content/drive/MyDrive/Thesis\"\n","FILEPATH = \"pol.txt\"\n","NUM_SAMPLE = 50000\n","VOCAB_SIZE = 20000\n","BATCH_SIZE = 64\n","GLOVE_DIM = 100\n","SOS = \"<sos>\"\n","EOS = \"<eos>\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"1edgrmVrIekS","executionInfo":{"status":"ok","timestamp":1684935608489,"user_tz":-120,"elapsed":5441,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"outputs":[],"source":["# Import other python scripts\n","import sys\n","sys.path.insert(0, PATH)\n","import preprocessing\n","import models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":213},"executionInfo":{"elapsed":37022,"status":"ok","timestamp":1684513483170,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"},"user_tz":-120},"id":"6xm5MMR6LW64","outputId":"087e5445-f78c-492a-88da-6bc400230627"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]},{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["# set-up Weights & Biases\n","!pip install wandb -qqq\n","import wandb\n","wandb.login()\n","from wandb.keras import WandbCallback"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"3QpwEvTgCPo5","executionInfo":{"status":"ok","timestamp":1684935634029,"user_tz":-120,"elapsed":337,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"outputs":[],"source":["# Other imports\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import callbacks\n","import numpy as np\n","import pandas as pd\n","import string"]},{"cell_type":"markdown","metadata":{"id":"xAcZGEHrCcuI"},"source":["### Prepare data"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2259,"status":"ok","timestamp":1684935643788,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"},"user_tz":-120},"id":"WOcrx9pDJEI4","outputId":"1ad882d9-516d-4502-8b23-970148db03c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-05-24 13:40:40--  http://www.manythings.org/anki/pol-eng.zip\n","Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n","Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1868937 (1.8M) [application/zip]\n","Saving to: ‘pol-eng.zip’\n","\n","pol-eng.zip         100%[===================>]   1.78M  1.94MB/s    in 0.9s    \n","\n","2023-05-24 13:40:42 (1.94 MB/s) - ‘pol-eng.zip’ saved [1868937/1868937]\n","\n"]}],"source":["# Import data\n","!wget http://www.manythings.org/anki/pol-eng.zip\n","!unzip -n -q pol-eng.zip "]},{"cell_type":"markdown","metadata":{"id":"i8jLq3t0SHLo"},"source":["Function to generate embeddings matrix from pre-trained embeddings.\n","GloVe embeddings will be used (https://nlp.stanford.edu/projects/glove/)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"tWrogsTUSVjj","executionInfo":{"status":"ok","timestamp":1684935646656,"user_tz":-120,"elapsed":323,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"outputs":[],"source":["def get_embedding_matrix(max_tokens, embed_dim):\n","    # load embeddings from a file\n","    glove_embeddings = {}\n","    with open(f\"{PATH}/Data/glove.6B.{embed_dim}d.txt\") as f:\n","        for line in f:\n","            values = line.split()\n","            word = values[0]\n","            vec = np.asarray(values[1:], dtype='float32')\n","            glove_embeddings[word] = vec\n","    \n","    # map embeddings from file to our vocabulary\n","    vocabulary = eng_vectorization.get_vocabulary()\n","    n_tokens = min(len(vocabulary) + 1, max_tokens)\n","    word_index = dict(zip(vocabulary, range(n_tokens)))\n","    embedding_matrix = np.zeros((max_tokens, embed_dim))\n","    for word, i in word_index.items():\n","        if i < max_tokens:\n","            embedding_vector = glove_embeddings.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[i] = embedding_vector\n","\n","    return embedding_matrix"]},{"cell_type":"markdown","metadata":{"id":"8k7-2c45jQO2"},"source":["Pre-process data"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"AYzB8xwKiz7p","executionInfo":{"status":"ok","timestamp":1684935670249,"user_tz":-120,"elapsed":17112,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"outputs":[],"source":["english_text, polish_text = preprocessing.read_file(FILEPATH, NUM_SAMPLE)\n","eng_train, eng_val, eng_test, pol_train, pol_val, pol_test = preprocessing.split_data(english_text, polish_text)\n","eng_vectorization, pol_vectorization, eng_len, pol_len = preprocessing.create_vectorization(eng_train, pol_train, VOCAB_SIZE)\n","train_ds, val_ds = preprocessing.create_datasets(eng_train, eng_val, pol_train, pol_val, eng_vectorization, pol_vectorization, BATCH_SIZE)\n","embedding_matrix = get_embedding_matrix(VOCAB_SIZE, GLOVE_DIM)"]},{"cell_type":"markdown","metadata":{"id":"r63wX8YaCiU1"},"source":["### Models"]},{"cell_type":"markdown","metadata":{"id":"ysyWqp_UsEDW"},"source":["We have 8 basic models defined:\n","\n","*   GRU\n","*   Bidirectional GRU\n","*   LSTM\n","*   Bidirectional LSTM\n","*   GRU with pretrained embeddings\n","*   Bidirectional GRU with pretrained embeddings\n","*   LSTM with pretrained embeddings\n","*   Bidirectional LSTM with pretrained embeddings\n","\n","In first stage, all of them will be trained with the same hyperparameters to choose the best architecture. Then hyperparameters will be fine-tuned for selected model. Ideally, hyperparameters should be fine-tuned for all architectures and only then the best model should be selected, but in the scope of this project this approach is unfeasible in terms of available resources.\n","\n","Shared hyperparameters are chosen arbitrarily, but they were based on Chollet's implementation. But as he had larger dataset (english - spanish language pair), embeddings dimention and number of cells in RNN layers were halved, to limit the number of parameters. In case of bidirectional layers, number of cells in each of two layers (forward and backward) was halved again.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ti-s0HlIsfx-","executionInfo":{"status":"ok","timestamp":1684935690918,"user_tz":-120,"elapsed":7,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"outputs":[],"source":["# Shared hyperparameters\n","EMBED_DIM = 128\n","LATENT_DIM = 512\n","DROPOUT = 0.5 \n","EPOCHS = 100\n","OPTIMIZER = \"rmsprop\""]},{"cell_type":"markdown","metadata":{"id":"M-jiFX0xDeji"},"source":["Create all the models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwrWJFq9uaFp"},"outputs":[],"source":["models_basic = {\n","    # at this step we do not need seperate encoder and decoder, only end-to-end model\n","    \"gru\": models.create_gru_model(VOCAB_SIZE, EMBED_DIM, LATENT_DIM, DROPOUT, OPTIMIZER)[0],\n","    \"bi_gru\": models.create_bi_gru_model(VOCAB_SIZE, EMBED_DIM, int(LATENT_DIM/2), DROPOUT, OPTIMIZER)[0],\n","    \"lstm\": models.create_lstm_model(VOCAB_SIZE, EMBED_DIM, LATENT_DIM, DROPOUT, OPTIMIZER)[0],\n","    \"bi_lstm\": models.create_bi_lstm_model(VOCAB_SIZE, EMBED_DIM, int(LATENT_DIM/2), DROPOUT, OPTIMIZER)[0],\n","    \"gru_glove\": models.create_gru_glove_model(VOCAB_SIZE, GLOVE_DIM, LATENT_DIM, DROPOUT, OPTIMIZER, embedding_matrix)[0],\n","    \"bi_gru_glove\": models.create_gru_glove_model(VOCAB_SIZE, GLOVE_DIM, int(LATENT_DIM/2), DROPOUT, OPTIMIZER, embedding_matrix)[0],\n","    \"lstm_glove\": models.create_lstm_glove_model(VOCAB_SIZE, GLOVE_DIM, LATENT_DIM, DROPOUT, OPTIMIZER, embedding_matrix)[0],\n","    \"bi_lstm_glove\": models.create_bi_lstm_glove_model(VOCAB_SIZE, GLOVE_DIM, int(LATENT_DIM/2), DROPOUT, OPTIMIZER, embedding_matrix)[0],\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4T1NvZZ11SIN"},"outputs":[],"source":["early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"okM5F_Bkj2z7"},"outputs":[],"source":["# Apart from ploting training results in Weights & Biases, \n","# best val_accuracy will be saved for each model to numerically verify the results\n","models_basic_history = {}\n","\n","for model_name in models_basic.keys():\n","\n","    # Weights & Biases callback\n","    wandb.init(\n","    project=\"Machine_translation\", \n","    name=f\"{model_name}\", \n","    config={\n","      \"epochs\": EPOCHS})\n","    config = wandb.config\n","    logging_callback = WandbCallback(log_evaluation=True, save_model=False)\n","\n","    model = models_basic.get(model_name)\n","    r = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds, callbacks=[early_stopping, logging_callback], verbose=2)\n","    models_basic_history[model_name] = max(r.history[\"val_accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W2Q2WuwPHkXR"},"outputs":[],"source":["# Save best val_accuracy for each model into csv file for future reference\n","df = pd.DataFrame(models_basic_history.items(), columns=[\"model\", \"val_accuracy\"])\n","df.to_csv(f\"{PATH}/Results/basic_models.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"NlOdxPIMvgqb"},"source":["Looking at the graphs in \"report.pdf\" and table in \"basic_models.csv\" it seems the best architecture consists of simple GRU with pretrained GloVe embeddings. This model will be selected for further fine-tuning."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"gLrrQJBPyXXD","executionInfo":{"status":"ok","timestamp":1684935722104,"user_tz":-120,"elapsed":4,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"outputs":[],"source":["GRU_GLOVE_MODEL_NAME = \"gru_glove\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_m0pMEBxNbf"},"outputs":[],"source":["# hyperparameter values for fine-tuning\n","latent_dims = [512, 1024]\n","dropouts = [0.5, 0.8]\n","optimizers = [\"rmsprop\", \"adam\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Axa1Iohsx_hV"},"outputs":[],"source":["gru_models_history = {}\n","\n","for latent_dim in latent_dims:\n","    for dropout in dropouts:\n","        for optimizer in optimizers:\n","\n","            model = models.create_gru_glove_model(VOCAB_SIZE, GLOVE_DIM, latent_dim, dropout, optimizer, embedding_matrix)[0]\n","            model_name = f\"{GRU_GLOVE_MODEL_NAME}_{latent_dim}_units_{dropout}_drop_{optimizer}\"\n","\n","            # Weights & Biases callback\n","            wandb.init(\n","            project=\"Machine_translation\", \n","            name=model_name, \n","            config={\n","                \"epochs\": EPOCHS,\n","                \"latent_dims\": latent_dim,\n","                \"dropouts\": dropout,\n","                \"optimizers\": optimizer})\n","            config = wandb.config\n","            logging_callback = WandbCallback(log_evaluation=True, save_model=False)\n","\n","            # Save best model for each hyperparameter config\n","            checkpoint_filepath = f\"{PATH}/Models/{model_name}.h5\"\n","            model_checkpoint_callback = callbacks.ModelCheckpoint(\n","                filepath=checkpoint_filepath,\n","                save_weights_only=True,\n","                monitor='val_accuracy',\n","                mode='max',\n","                save_best_only=True)\n","            \n","            r = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds, \n","                          callbacks=[early_stopping, logging_callback, model_checkpoint_callback], \n","                          verbose=2)\n","            gru_models_history[model_name] = max(r.history[\"val_accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"61QL9Iq0X36t"},"outputs":[],"source":["# Save best val_accuracy for each model into csv file for future reference\n","df = pd.DataFrame(gru_models_history.items(), columns=[\"model\", \"val_accuracy\"])\n","df.to_csv(f\"{PATH}/Results/gru_glove_models.csv\", index=False)"]},{"cell_type":"markdown","source":["### Evaluation"],"metadata":{"id":"6iHRyy1bhEtE"}},{"cell_type":"markdown","source":["The best set of hyperparameters, that allowed the model to reach accuracy of more than 60%, is: \n","\n","*   latent_dim = 1024\n","*   dropout = 0.8\n","*   optimizer = adam"],"metadata":{"id":"p1KFoqmshGsQ"}},{"cell_type":"code","source":["# The best values for hyperparameters\n","best_latent_dim = 1024\n","best_dropout = 0.8\n","best_optimizer = \"adam\"\n","best_model_name = f\"{GRU_GLOVE_MODEL_NAME}_{best_latent_dim}_units_{best_dropout}_drop_{best_optimizer}\""],"metadata":{"id":"QErQkPpUmaTJ","executionInfo":{"status":"ok","timestamp":1684935732536,"user_tz":-120,"elapsed":21,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["model, encoder, decoder = models.create_gru_glove_model(VOCAB_SIZE, GLOVE_DIM, best_latent_dim, best_dropout, best_optimizer, embedding_matrix)\n","model.load_weights(f\"{PATH}/Models/{best_model_name}.h5\")"],"metadata":{"id":"4Nh1viIAbWa4","executionInfo":{"status":"ok","timestamp":1684935745028,"user_tz":-120,"elapsed":6511,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# function for translating one sentence using encoder - decoder pair\n","pol_vocab = pol_vectorization.get_vocabulary()\n","pol_index_lookup = dict(zip(range(len(pol_vocab)), pol_vocab))\n","def decode_sequence_gru(input_sentence):\n","    input_sentence_tok = eng_vectorization([input_sentence])\n","    states = encoder.predict(input_sentence_tok, verbose=0)\n","    target_sentence = np.zeros((1,1))\n","    target_sentence[0, 0] = pol_vocab.index(SOS)\n","    decoded_sentence = []\n","    for _ in range(pol_len):\n","        decoder_output, h = decoder.predict(\n","            [target_sentence] + [states],\n","            verbose=0\n","        )\n","        next_token_index = np.argmax(decoder_output[0, 0, :])\n","        next_token = pol_index_lookup[next_token_index]\n","        if next_token == EOS:\n","            break\n","        decoded_sentence.append(next_token)\n","        target_sentence[0, 0] = next_token_index\n","        states = [h]\n","    return ' '.join(decoded_sentence)"],"metadata":{"id":"_Pn7Jv3HbWYg","executionInfo":{"status":"ok","timestamp":1684935914412,"user_tz":-120,"elapsed":17,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["Create translations"],"metadata":{"id":"n0W9cF3PUyte"}},{"cell_type":"code","source":["gru_translations = []\n","for eng_sentence in eng_test:\n","    gru_translations.append(decode_sequence_gru(eng_sentence))"],"metadata":{"id":"VVh9WuiKUtX2","executionInfo":{"status":"ok","timestamp":1684937770734,"user_tz":-120,"elapsed":1812024,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# save translations to file for future reference\n","import pickle\n","with open(f\"{PATH}/Results/gru_translations.pickle\", \"wb\") as fp:\n","    pickle.dump(gru_translations, fp)"],"metadata":{"id":"ngfp0qniIw4r","executionInfo":{"status":"ok","timestamp":1684938246608,"user_tz":-120,"elapsed":355,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["Translations using pre-trained model\n","\n","To compare how our custom model really performes, it is useful to confront it with some available open-source model for this task.\n","\n","In this case I will use mT5 model fine-tuned for Polish-English and English-Polish translation, shared by Sławomir Dadas. Link to his git repo: https://github.com/sdadas/polish-nlp-resources#t5-based-models"],"metadata":{"id":"RDar1GncJ-o1"}},{"cell_type":"code","source":["# !pip install sentencepiece\n","!pip install transformers\n","from transformers import pipeline"],"metadata":{"id":"pAEaNsCYbWQt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import pipeline\n","generator = pipeline(\"translation\", model=\"sdadas/mt5-base-translator-en-pl\")\n","translations_mt5 = generator(eng_test, max_length=pol_len)\n","translations_mt5 = [preprocessing.clean_sentence(translation[\"translation_text\"])\n","                    for translation in translations_mt5]"],"metadata":{"id":"Dftn7Yg-bWGc","executionInfo":{"status":"ok","timestamp":1684943512427,"user_tz":-120,"elapsed":4262376,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# save translations to file for future reference\n","with open(f\"{PATH}/Results/translations_mt5.pickle\", \"wb\") as fp:\n","    pickle.dump(translations_mt5, fp)"],"metadata":{"id":"mBPm8ch1dlMS","executionInfo":{"status":"ok","timestamp":1684943575394,"user_tz":-120,"elapsed":7,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["##### Qualitative evaluation"],"metadata":{"id":"qnEkB8K2duRE"}},{"cell_type":"markdown","source":["Let's look at first ten translations and inspect them manually."],"metadata":{"id":"lPiFhPBad1ev"}},{"cell_type":"markdown","source":["Custom GRU model"],"metadata":{"id":"TFkYWbzZd8hi"}},{"cell_type":"code","source":["for i in range(10):\n","    print(f\"English sentence: {eng_test[i]}\")\n","    print(f\"GRU model translation: {gru_translations[i]}\")\n","    print(f\"Ground truth translation: {preprocessing.clean_sentence(pol_test[i])}\")\n","    print(\"-----\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JD3PTU0rd-Po","executionInfo":{"status":"ok","timestamp":1684943895769,"user_tz":-120,"elapsed":10,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}},"outputId":"e7a7e5dc-b2e7-4a04-a82c-16a25eca29f0"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["English sentence: She arrived when we were about to leave.\n","GRU model translation: poszła na niego czekać\n","Ground truth translation: przyjechała akurat w momencie gdy mieliśmy wychodzić\n","-----\n","English sentence: Tom is walking.\n","GRU model translation: tom jest zajęty\n","Ground truth translation: tom idzie\n","-----\n","English sentence: I didn't want you to know.\n","GRU model translation: nie chciałem żebyś wiedział\n","Ground truth translation: nie chciałem żebyś wiedział\n","-----\n","English sentence: Do you need time to think it over?\n","GRU model translation: czy potrzebujesz tego czasu\n","Ground truth translation: czy potrzebujesz czasu żeby to przemyśleć\n","-----\n","English sentence: You look like an imbecile.\n","GRU model translation: wyglądasz na wykończonego\n","Ground truth translation: wyglądasz na durnia\n","-----\n","English sentence: A lot of people are going to tell you that you shouldn't have done that.\n","GRU model translation: wiele osób o tym co chcesz zrobić to co zrobił\n","Ground truth translation: wiele osób ci powie że nie powinieneś był tego robić\n","-----\n","English sentence: We'll get another chance.\n","GRU model translation: dowiemy się\n","Ground truth translation: dostaniemy kolejną szansę\n","-----\n","English sentence: Would you mind reading a bedtime story to Tom?\n","GRU model translation: czy mógłbyś bajkę na dobranoc\n","Ground truth translation: przeczytałby pan tomowi bajkę na dobranoc\n","-----\n","English sentence: I really want to see you.\n","GRU model translation: naprawdę chcę cię zobaczyć\n","Ground truth translation: naprawdę chcę cię zobaczyć\n","-----\n","English sentence: Our teacher is a real idiot.\n","GRU model translation: nasz nauczyciel jest kanadyjczykiem\n","Ground truth translation: nasz nauczyciel to prawdziwy idiota\n","-----\n"]}]},{"cell_type":"markdown","source":["Some translations are very precise, and even some that are not completely correct give some indication of learning. For example in the last one, model corrctly predicted \"nasz nauczyciel\", but failed with the rest of the sentence."],"metadata":{"id":"WXWDf39seg8Z"}},{"cell_type":"markdown","source":["Pre-trained mT5 model"],"metadata":{"id":"fDI124ebe0el"}},{"cell_type":"code","source":["for i in range(10):\n","    print(f\"English sentence: {eng_test[i]}\")\n","    print(f\"mT5 model translation: {translations_mt5[i]}\")\n","    print(f\"Ground truth translation: {preprocessing.clean_sentence(pol_test[i])}\")\n","    print(\"-----\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kfYDMYxZe28I","executionInfo":{"status":"ok","timestamp":1684943921012,"user_tz":-120,"elapsed":13,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}},"outputId":"28d6a5fb-7464-4cd7-99f5-c28734055c80"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["English sentence: She arrived when we were about to leave.\n","mT5 model translation: przyszła kiedy mieliśmy wyjechać\n","Ground truth translation: przyjechała akurat w momencie gdy mieliśmy wychodzić\n","-----\n","English sentence: Tom is walking.\n","mT5 model translation: tom idzie\n","Ground truth translation: tom idzie\n","-----\n","English sentence: I didn't want you to know.\n","mT5 model translation: nie chciałem żebyś wiedział\n","Ground truth translation: nie chciałem żebyś wiedział\n","-----\n","English sentence: Do you need time to think it over?\n","mT5 model translation: potrzebujesz czasu żeby to przemyśleć\n","Ground truth translation: czy potrzebujesz czasu żeby to przemyśleć\n","-----\n","English sentence: You look like an imbecile.\n","mT5 model translation: wyglądasz jak imbecyl\n","Ground truth translation: wyglądasz na durnia\n","-----\n","English sentence: A lot of people are going to tell you that you shouldn't have done that.\n","mT5 model translation: wielu ludzi powie ci że nie powinieneś tego robić\n","Ground truth translation: wiele osób ci powie że nie powinieneś był tego robić\n","-----\n","English sentence: We'll get another chance.\n","mT5 model translation: będziemy mieli kolejną szansę\n","Ground truth translation: dostaniemy kolejną szansę\n","-----\n","English sentence: Would you mind reading a bedtime story to Tom?\n","mT5 model translation: czy mógłbyś przeczytać tomowi bajkę na dobranoc\n","Ground truth translation: przeczytałby pan tomowi bajkę na dobranoc\n","-----\n","English sentence: I really want to see you.\n","mT5 model translation: naprawdę chcę cię widzieć\n","Ground truth translation: naprawdę chcę cię zobaczyć\n","-----\n","English sentence: Our teacher is a real idiot.\n","mT5 model translation: nasz nauczyciel to prawdziwy idiota\n","Ground truth translation: nasz nauczyciel to prawdziwy idiota\n","-----\n"]}]},{"cell_type":"markdown","source":["Pretrained model is basically always correct. Even when translation does not match \"ground truth\", Polish speaker can judje that the translation is correct."],"metadata":{"id":"UJh47KG6fDD7"}},{"cell_type":"markdown","source":["##### Quantitative evaluation"],"metadata":{"id":"0X6LMjCjfSPf"}},{"cell_type":"markdown","source":["The metric that will be used for final evaluation is BLEU score: https://en.wikipedia.org/wiki/BLEU\n","\n","Scores for 1-grams will be used, and cumulative scores for 2, 3 and 4-grams."],"metadata":{"id":"m2Roqa92fXbX"}},{"cell_type":"code","source":["import nltk\n","from nltk.translate.bleu_score import sentence_bleu"],"metadata":{"id":"JUuDKW7Dfn24","executionInfo":{"status":"ok","timestamp":1684944573691,"user_tz":-120,"elapsed":5,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["reference = [preprocessing.clean_sentence(translation).split() for translation in pol_test]\n","translations_len = len(reference)"],"metadata":{"id":"nXAxx3eLfpxa","executionInfo":{"status":"ok","timestamp":1684945237136,"user_tz":-120,"elapsed":13,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["# For custom model translations\n","individual_scores_gru_1 = np.zeros(translations_len)\n","individual_scores_gru_2 = np.zeros(translations_len)\n","individual_scores_gru_3 = np.zeros(translations_len)\n","individual_scores_gru_4 = np.zeros(translations_len)\n","candidates_gru = [translation.split() for translation in gru_translations]\n","\n","for i in range(translations_len):\n","    individual_scores_gru_1[i] = sentence_bleu([reference[i]], candidates_gru[i], weights=(1, 0, 0, 0))\n","    individual_scores_gru_2[i] = sentence_bleu([reference[i]], candidates_gru[i], weights=(0.5, 0.5, 0, 0))\n","    individual_scores_gru_3[i] = sentence_bleu([reference[i]], candidates_gru[i], weights=(0.33, 0.33, 0.33, 0))\n","    individual_scores_gru_4[i] = sentence_bleu([reference[i]], candidates_gru[i], weights=(0.25, 0.25, 0.25, 0.25))"],"metadata":{"id":"RLNYmhRDf7xg","executionInfo":{"status":"ok","timestamp":1684945511025,"user_tz":-120,"elapsed":850,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["print(f\"BLEU 1-gram score for GRU translations: {np.mean(individual_scores_gru_1)}\")\n","print(f\"BLEU 2-gram score for GRU translations: {np.mean(individual_scores_gru_2)}\")\n","print(f\"BLEU 3-gram score for GRU translations: {np.mean(individual_scores_gru_3)}\")\n","print(f\"BLEU 4-gram score for GRU translations: {np.mean(individual_scores_gru_4)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHrT4JcdifDc","executionInfo":{"status":"ok","timestamp":1684945513640,"user_tz":-120,"elapsed":337,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}},"outputId":"44929ad4-e9d5-4413-a3b0-19a8bab8eded"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["BLEU 1-gram score for GRU translations: 0.42312221459802907\n","BLEU 2-gram score for GRU translations: 0.24776813091318406\n","BLEU 3-gram score for GRU translations: 0.1296367321528724\n","BLEU 4-gram score for GRU translations: 0.05721072461345969\n"]}]},{"cell_type":"markdown","source":["Let's look for individual scores for 1-gram."],"metadata":{"id":"5Rb4SWctimOY"}},{"cell_type":"code","source":["np.set_printoptions(suppress=True)\n","gru_scores, counts = np.unique(individual_scores_gru_1, return_counts=True)\n","print(np.asarray((gru_scores, counts)).T)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fw_RZ5D_is1w","executionInfo":{"status":"ok","timestamp":1684945473556,"user_tz":-120,"elapsed":8,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}},"outputId":"d1daf8c8-9a0a-440b-8b8a-e3225a15ebc0"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["[[  0.         590.        ]\n"," [  0.04511176   1.        ]\n"," [  0.04931939   1.        ]\n"," [  0.05882353   1.        ]\n"," [  0.06062469   1.        ]\n"," [  0.06666667   1.        ]\n"," [  0.06690768   1.        ]\n"," [  0.07142857   1.        ]\n"," [  0.0716262    1.        ]\n"," [  0.07243303   1.        ]\n"," [  0.07357589   1.        ]\n"," [  0.07692308   6.        ]\n"," [  0.07961459   1.        ]\n"," [  0.08333333   2.        ]\n"," [  0.08556952   2.        ]\n"," [  0.08786571   1.        ]\n"," [  0.09048374   1.        ]\n"," [  0.09090909   6.        ]\n"," [  0.09196986   2.        ]\n"," [  0.09306272   2.        ]\n"," [  0.09622061   1.        ]\n"," [  0.0973501    2.        ]\n"," [  0.09942659   2.        ]\n"," [  0.1         11.        ]\n"," [  0.1073539    5.        ]\n"," [  0.10976233   3.        ]\n"," [  0.11031211   5.        ]\n"," [  0.11111111  18.        ]\n"," [  0.11409269   1.        ]\n"," [  0.11540662   1.        ]\n"," [  0.11764706   1.        ]\n"," [  0.11809164   4.        ]\n"," [  0.11942189   6.        ]\n"," [  0.12262648   2.        ]\n"," [  0.1238397    4.        ]\n"," [  0.125       34.        ]\n"," [  0.13406401  10.        ]\n"," [  0.13533528   3.        ]\n"," [  0.14108029   6.        ]\n"," [  0.14248453   1.        ]\n"," [  0.14285714  59.        ]\n"," [  0.14486607   2.        ]\n"," [  0.14816364   2.        ]\n"," [  0.15159144   1.        ]\n"," [  0.15163266  15.        ]\n"," [  0.15570161   1.        ]\n"," [  0.15922918   1.        ]\n"," [  0.16374615  33.        ]\n"," [  0.16666667  78.        ]\n"," [  0.17113904  21.        ]\n"," [  0.17182232   1.        ]\n"," [  0.17573143   1.        ]\n"," [  0.17794165   2.        ]\n"," [  0.17973159   2.        ]\n"," [  0.18096748   2.        ]\n"," [  0.18181818  10.        ]\n"," [  0.18393972  10.        ]\n"," [  0.18612545   2.        ]\n"," [  0.1947002   49.        ]\n"," [  0.19885318   3.        ]\n"," [  0.2        166.        ]\n"," [  0.20072304   1.        ]\n"," [  0.20217689   2.        ]\n"," [  0.21428571   2.        ]\n"," [  0.2147078    6.        ]\n"," [  0.2172991    2.        ]\n"," [  0.21952465   5.        ]\n"," [  0.22062423   4.        ]\n"," [  0.22222222  25.        ]\n"," [  0.227449     1.        ]\n"," [  0.23076923   3.        ]\n"," [  0.23618328   3.        ]\n"," [  0.23884377  80.        ]\n"," [  0.24525296   5.        ]\n"," [  0.24561923   1.        ]\n"," [  0.2476794   12.        ]\n"," [  0.25       191.        ]\n"," [  0.25773348   4.        ]\n"," [  0.26812802  11.        ]\n"," [  0.27145123   1.        ]\n"," [  0.27272727   3.        ]\n"," [  0.27918817   2.        ]\n"," [  0.28216057  20.        ]\n"," [  0.28571429  72.        ]\n"," [  0.2865048    1.        ]\n"," [  0.29205029   6.        ]\n"," [  0.29632729   1.        ]\n"," [  0.29827977   2.        ]\n"," [  0.3         13.        ]\n"," [  0.30326533  61.        ]\n"," [  0.30668147   1.        ]\n"," [  0.30769231   6.        ]\n"," [  0.3220617   10.        ]\n"," [  0.32269607   1.        ]\n"," [  0.3274923   31.        ]\n"," [  0.32928698   4.        ]\n"," [  0.33093634   3.        ]\n"," [  0.33333333 305.        ]\n"," [  0.34227808  16.        ]\n"," [  0.34621986   1.        ]\n"," [  0.35294118   1.        ]\n"," [  0.35427491   2.        ]\n"," [  0.35588329   2.        ]\n"," [  0.35714286   3.        ]\n"," [  0.35826566  16.        ]\n"," [  0.36193497   1.        ]\n"," [  0.36363636   6.        ]\n"," [  0.36787944   7.        ]\n"," [  0.3715191   13.        ]\n"," [  0.37225089   4.        ]\n"," [  0.375       45.        ]\n"," [  0.38461538   1.        ]\n"," [  0.38940039  55.        ]\n"," [  0.39770636   3.        ]\n"," [  0.4        161.        ]\n"," [  0.40219203  11.        ]\n"," [  0.40435377   4.        ]\n"," [  0.41666667   4.        ]\n"," [  0.42324086  18.        ]\n"," [  0.42749682   1.        ]\n"," [  0.42857143  61.        ]\n"," [  0.4294156    8.        ]\n"," [  0.43904931   2.        ]\n"," [  0.44124845   5.        ]\n"," [  0.44444444  10.        ]\n"," [  0.44485411   1.        ]\n"," [  0.45241871   1.        ]\n"," [  0.45454545   1.        ]\n"," [  0.45489799  19.        ]\n"," [  0.46153846   1.        ]\n"," [  0.46531361   1.        ]\n"," [  0.47236655   1.        ]\n"," [  0.47768754  70.        ]\n"," [  0.48675049   1.        ]\n"," [  0.49123845  28.        ]\n"," [  0.4953588    8.        ]\n"," [  0.49713295   2.        ]\n"," [  0.5        527.        ]\n"," [  0.50544222   2.        ]\n"," [  0.51341712   4.        ]\n"," [  0.53382494   1.        ]\n"," [  0.53625604   8.        ]\n"," [  0.5367695    1.        ]\n"," [  0.53846154   2.        ]\n"," [  0.54545455   1.        ]\n"," [  0.55156056   3.        ]\n"," [  0.55555556   4.        ]\n"," [  0.56432115  15.        ]\n"," [  0.57142857  46.        ]\n"," [  0.58333333   2.        ]\n"," [  0.58410059  42.        ]\n"," [  0.59710943   3.        ]\n"," [  0.6        108.        ]\n"," [  0.60653066  28.        ]\n"," [  0.6191985    9.        ]\n"," [  0.625       16.        ]\n"," [  0.63636364   2.        ]\n"," [  0.64412339   1.        ]\n"," [  0.6549846   33.        ]\n"," [  0.66666667 306.        ]\n"," [  0.67032005   5.        ]\n"," [  0.69598614   1.        ]\n"," [  0.7          1.        ]\n"," [  0.70540144   8.        ]\n"," [  0.71176658   1.        ]\n"," [  0.71428571  25.        ]\n"," [  0.71653131  29.        ]\n"," [  0.7430382    1.        ]\n"," [  0.75       183.        ]\n"," [  0.75147729   2.        ]\n"," [  0.77218479   1.        ]\n"," [  0.77777778   4.        ]\n"," [  0.77880078  21.        ]\n"," [  0.8         87.        ]\n"," [  0.81873075   7.        ]\n"," [  0.83333333  38.        ]\n"," [  0.84648172   5.        ]\n"," [  0.85714286   7.        ]\n"," [  0.8668779    1.        ]\n"," [  0.875        7.        ]\n"," [  0.88888889   3.        ]\n"," [  1.         368.        ]]\n"]}]},{"cell_type":"markdown","source":["We can see there were 368 sentences that model predicted exactly right, and 590 that do not match at all."],"metadata":{"id":"OCh0pz7-iqQw"}},{"cell_type":"markdown","source":["The same evaluation for mT5."],"metadata":{"id":"rX9wxjHSlPok"}},{"cell_type":"code","source":["# For pretrained mT5 model translations\n","individual_scores_mt5_1 = np.zeros(translations_len)\n","individual_scores_mt5_2 = np.zeros(translations_len)\n","individual_scores_mt5_3 = np.zeros(translations_len)\n","individual_scores_mt5_4 = np.zeros(translations_len)\n","candidates_mt5 = [translation.split() for translation in translations_mt5]\n","\n","for i in range(translations_len):\n","    individual_scores_mt5_1[i] = sentence_bleu([reference[i]], candidates_mt5[i], weights=(1, 0, 0, 0))\n","    individual_scores_mt5_2[i] = sentence_bleu([reference[i]], candidates_mt5[i], weights=(0.5, 0.5, 0, 0))\n","    individual_scores_mt5_3[i] = sentence_bleu([reference[i]], candidates_mt5[i], weights=(0.33, 0.33, 0.33, 0))\n","    individual_scores_mt5_4[i] = sentence_bleu([reference[i]], candidates_mt5[i], weights=(0.25, 0.25, 0.25, 0.25))"],"metadata":{"id":"1P-Cb_9NlUBS","executionInfo":{"status":"ok","timestamp":1684945634968,"user_tz":-120,"elapsed":1477,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":117,"outputs":[]},{"cell_type":"code","source":["print(f\"BLEU 1-gram score for mT5 translations: {np.mean(individual_scores_mt5_1)}\")\n","print(f\"BLEU 2-gram score for mT5 translations: {np.mean(individual_scores_mt5_2)}\")\n","print(f\"BLEU 3-gram score for mT5 translations: {np.mean(individual_scores_mt5_3)}\")\n","print(f\"BLEU 4-gram score for mT5 translations: {np.mean(individual_scores_mt5_4)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m6UwFr41liCj","executionInfo":{"status":"ok","timestamp":1684945677779,"user_tz":-120,"elapsed":4,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}},"outputId":"981b2b6f-6a64-4fa3-e063-2c531b3ee69a"},"execution_count":118,"outputs":[{"output_type":"stream","name":"stdout","text":["BLEU 1-gram score for mT5 translations: 0.688217699755092\n","BLEU 2-gram score for mT5 translations: 0.5484003852145302\n","BLEU 3-gram score for mT5 translations: 0.39269416392431133\n","BLEU 4-gram score for mT5 translations: 0.2364343227115686\n"]}]},{"cell_type":"markdown","source":["Even pretrained model only got around 0.69, but as we saw it might be the case that translation is correct, it just does not match exactly \"ground truth\". Where we can see bigger differences with custom model is on 2, 3, and 4-gram scores, which are significantly higher. "],"metadata":{"id":"O676nDy7lt0A"}},{"cell_type":"markdown","source":["##### Evaluate on wikipedia"],"metadata":{"id":"t1Xs3TugmGQo"}},{"cell_type":"markdown","source":["File wikipedia.ipynb created a file with translated wikipedia articla about Artificial Intelligence."],"metadata":{"id":"AfpUfGRcyhWN"}},{"cell_type":"code","source":["df = pd.read_csv(f\"{PATH}/Data/wikipedia_translation.csv\", index_col=0)\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"xkrcJoUDmMOC","executionInfo":{"status":"ok","timestamp":1684945890772,"user_tz":-120,"elapsed":17,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}},"outputId":"894cd299-40eb-4522-8cbb-57620f660530"},"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             english  \\\n","0  Artificial intelligence (AI) is intelligence—p...   \n","1  Example tasks in which this is done include sp...   \n","2  AI applications include advanced web search en...   \n","3  As machines become increasingly capable, tasks...   \n","4  For instance, optical character recognition is...   \n","\n","                                              polish  \n","0  Sztuczna inteligencja (AI) to inteligencja - p...  \n","1  Przykładowe zadania, w których jest to wykonyw...  \n","2  Zastosowania sztucznej inteligencji obejmują z...  \n","3  W miarę jak maszyny stają się coraz bardziej w...  \n","4  Na przykład optyczne rozpoznawanie znaków jest...  "],"text/html":["\n","  <div id=\"df-7504e33e-16a2-42f7-b4e6-d7daaade35f2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>english</th>\n","      <th>polish</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Artificial intelligence (AI) is intelligence—p...</td>\n","      <td>Sztuczna inteligencja (AI) to inteligencja - p...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Example tasks in which this is done include sp...</td>\n","      <td>Przykładowe zadania, w których jest to wykonyw...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AI applications include advanced web search en...</td>\n","      <td>Zastosowania sztucznej inteligencji obejmują z...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>As machines become increasingly capable, tasks...</td>\n","      <td>W miarę jak maszyny stają się coraz bardziej w...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>For instance, optical character recognition is...</td>\n","      <td>Na przykład optyczne rozpoznawanie znaków jest...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7504e33e-16a2-42f7-b4e6-d7daaade35f2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7504e33e-16a2-42f7-b4e6-d7daaade35f2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7504e33e-16a2-42f7-b4e6-d7daaade35f2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":123}]},{"cell_type":"code","source":["eng_wiki = np.asarray(df[\"english\"])\n","pol_wiki = np.asarray(df[\"polish\"])"],"metadata":{"id":"I04x-sMOmj49","executionInfo":{"status":"ok","timestamp":1684945957281,"user_tz":-120,"elapsed":316,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":126,"outputs":[]},{"cell_type":"code","source":["gru_translations_wiki = []\n","for eng_sentence in eng_wiki:\n","    gru_translations_wiki.append(decode_sequence_gru(eng_sentence))"],"metadata":{"id":"kTUaCz8Om084","executionInfo":{"status":"ok","timestamp":1684946685302,"user_tz":-120,"elapsed":315349,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":133,"outputs":[]},{"cell_type":"code","source":["with open(f\"{PATH}/Results/gru_translations_wiki.pickle\", \"wb\") as fp:\n","    pickle.dump(gru_translations_wiki, fp)"],"metadata":{"id":"QdjgxqOnod8A","executionInfo":{"status":"ok","timestamp":1684946710749,"user_tz":-120,"elapsed":426,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":134,"outputs":[]},{"cell_type":"code","source":["translations_mt5_wiki = generator(list(eng_wiki), max_length=400)\n","translations_mt5_wiki = [preprocessing.clean_sentence(translation[\"translation_text\"])\n","                        for translation in translations_mt5_wiki]"],"metadata":{"id":"cxAGyN5uol5m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(f\"{PATH}/Results/translations_mt5_wiki.pickle\", \"wb\") as fp:\n","    pickle.dump(translations_mt5_wiki, fp)"],"metadata":{"id":"Eo4wH5bEoyl8","executionInfo":{"status":"ok","timestamp":1684948221481,"user_tz":-120,"elapsed":949,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":141,"outputs":[]},{"cell_type":"code","source":["for i in range(5):\n","    print(f\"English sentence: {eng_wiki[i]}\")\n","    print(f\"GRU model translation: {gru_translations_wiki[i]}\")\n","    print(f\"Ground truth translation: {preprocessing.clean_sentence(pol_wiki[i])}\")\n","    print(\"-----\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zDXMmtnvoYHh","executionInfo":{"status":"ok","timestamp":1684948223797,"user_tz":-120,"elapsed":10,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}},"outputId":"7490d4b8-a6b6-4f2e-e936-1b20e72d808a"},"execution_count":142,"outputs":[{"output_type":"stream","name":"stdout","text":["English sentence: Artificial intelligence (AI) is intelligence—perceiving, synthesizing, and inferring information—demonstrated by machines, as opposed to intelligence displayed by humans or by other animals.\n","GRU model translation: nikiel to że nie da się wyuczyć języka obcego jest niewinny ale wsadzili go do samobójstwa\n","Ground truth translation: sztuczna inteligencja ai to inteligencja  postrzeganie synteza i wnioskowanie informacji  demonstrowana przez maszyny w przeciwieństwie do inteligencji wykazywanej przez ludzi lub inne zwierzęta\n","-----\n","English sentence: Example tasks in which this is done include speech recognition, computer vision, translation between (natural) languages, as well as other mappings of inputs.\n","GRU model translation: te dane w dzisiejszych czasach niewiele osób mówiących się z rodzimymi użytkownikami\n","Ground truth translation: przykładowe zadania w których jest to wykonywane obejmują rozpoznawanie mowy widzenie komputerowe tłumaczenie między naturalnymi językami a także inne odwzorowania danych wejściowych\n","-----\n","English sentence: AI applications include advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Waymo), generative or creative tools (ChatGPT and AI art), automated decision-making, and competing at the highest level in strategic game systems (such as chess and Go).\n","GRU model translation: uczę się angielskiego w szkole ale muszę się pospieszyć z powodu żeby móc wziąć życie w ciągu roku\n","Ground truth translation: zastosowania sztucznej inteligencji obejmują zaawansowane wyszukiwarki internetowe np google search systemy rekomendacji używane przez youtube amazon i netflix rozumienie ludzkiej mowy takie jak siri i alexa autonomiczne samochody np waymo narzędzia generatywne lub kreatywne chatgpt i sztuka ai zautomatyzowane podejmowanie decyzji i konkurowanie na najwyższym poziomie w systemach gier strategicznych takich jak szachy i go\n","-----\n","English sentence: As machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon known as the AI effect.\n","GRU model translation: jak dotąd nie jest łatwo wyzbyć się bardziej złych nawyków\n","Ground truth translation: w miarę jak maszyny stają się coraz bardziej wydajne zadania uważane za wymagające inteligencji są często usuwane z definicji sztucznej inteligencji co jest zjawiskiem znanym jako efekt sztucznej inteligencji\n","-----\n","English sentence: For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.\n","GRU model translation: w tej chwili nie jest łatwo się obcego będzie mógł grać na oboju\n","Ground truth translation: na przykład optyczne rozpoznawanie znaków jest często wykluczane z rzeczy uważanych za sztuczną inteligencję ponieważ stało się rutynową technologią\n","-----\n"]}]},{"cell_type":"markdown","source":["Unfortunately translations generated by the custom GRU model are of very poor quality."],"metadata":{"id":"bGsTil9xy_T7"}},{"cell_type":"code","source":["for i in range(5):\n","    print(f\"English sentence: {eng_wiki[i]}\")\n","    print(f\"mT5 model translation: {translations_mt5_wiki[i]}\")\n","    print(f\"Ground truth translation: {preprocessing.clean_sentence(pol_wiki[i])}\")\n","    print(\"-----\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7XaJdscolUo","executionInfo":{"status":"ok","timestamp":1684948226265,"user_tz":-120,"elapsed":410,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}},"outputId":"e37434e4-de86-4240-9405-3ec52e34e1f0"},"execution_count":143,"outputs":[{"output_type":"stream","name":"stdout","text":["English sentence: Artificial intelligence (AI) is intelligence—perceiving, synthesizing, and inferring information—demonstrated by machines, as opposed to intelligence displayed by humans or by other animals.\n","mT5 model translation: sztuczna inteligencja ai to inteligencja – postrzeganie synteza i wyciąganie informacji – demonstrowana przez maszyny w przeciwieństwie do inteligencji wyświetlanej przez ludzi lub inne zwierzęta\n","Ground truth translation: sztuczna inteligencja ai to inteligencja  postrzeganie synteza i wnioskowanie informacji  demonstrowana przez maszyny w przeciwieństwie do inteligencji wykazywanej przez ludzi lub inne zwierzęta\n","-----\n","English sentence: Example tasks in which this is done include speech recognition, computer vision, translation between (natural) languages, as well as other mappings of inputs.\n","mT5 model translation: przykładowe zadania w których jest to wykonywane to rozpoznawanie mowy widzenie komputerowe tłumaczenie między naturalnymi językami a także inne mapowanie wejścia\n","Ground truth translation: przykładowe zadania w których jest to wykonywane obejmują rozpoznawanie mowy widzenie komputerowe tłumaczenie między naturalnymi językami a także inne odwzorowania danych wejściowych\n","-----\n","English sentence: AI applications include advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Waymo), generative or creative tools (ChatGPT and AI art), automated decision-making, and competing at the highest level in strategic game systems (such as chess and Go).\n","mT5 model translation: aplikacje ai obejmują zaawansowane wyszukiwarki internetowe np google search systemy rekomendacji stosowane przez youtube amazon i netflix zrozumienie ludzkiej mowy np siri i alexa autonomiczne samochody np waymo narzędzia generacyjne lub kreatywne chatgpt i sztukę sztucznej inteligencji automatyczne podejmowanie decyzji i konkurowanie na najwyższym poziomie w strategicznych systemach gier np szachy i go\n","Ground truth translation: zastosowania sztucznej inteligencji obejmują zaawansowane wyszukiwarki internetowe np google search systemy rekomendacji używane przez youtube amazon i netflix rozumienie ludzkiej mowy takie jak siri i alexa autonomiczne samochody np waymo narzędzia generatywne lub kreatywne chatgpt i sztuka ai zautomatyzowane podejmowanie decyzji i konkurowanie na najwyższym poziomie w systemach gier strategicznych takich jak szachy i go\n","-----\n","English sentence: As machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon known as the AI effect.\n","mT5 model translation: w miarę jak maszyny stają się coraz bardziej zdolne zadania uważane za wymagające „inteligencji” są często usuwane z definicji ai zjawiska znanego jako efekt ai\n","Ground truth translation: w miarę jak maszyny stają się coraz bardziej wydajne zadania uważane za wymagające inteligencji są często usuwane z definicji sztucznej inteligencji co jest zjawiskiem znanym jako efekt sztucznej inteligencji\n","-----\n","English sentence: For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.\n","mT5 model translation: na przykład optyczne rozpoznawanie znaków jest często wykluczone z rzeczy uważanych za sztuczną inteligencję która stała się rutynowym technologią\n","Ground truth translation: na przykład optyczne rozpoznawanie znaków jest często wykluczane z rzeczy uważanych za sztuczną inteligencję ponieważ stało się rutynową technologią\n","-----\n"]}]},{"cell_type":"code","source":["reference_wiki = [preprocessing.clean_sentence(translation).split() for translation in pol_wiki]\n","translations_wiki_len = len(reference_wiki)"],"metadata":{"id":"8oZyRmdUquPz","executionInfo":{"status":"ok","timestamp":1684948232009,"user_tz":-120,"elapsed":336,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}}},"execution_count":144,"outputs":[]},{"cell_type":"code","source":["individual_scores_gru_wiki = np.zeros(translations_wiki_len)\n","candidates_gru_wiki = [translation.split() for translation in gru_translations_wiki]\n","\n","for i in range(translations_wiki_len):\n","    individual_scores_gru_wiki[i] = sentence_bleu([reference_wiki[i]], candidates_gru_wiki[i], weights=(1, 0, 0, 0))\n","\n","print(f\"BLEU 1-gram score for GRU translations: {np.mean(individual_scores_gru_wiki)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BFShkNA0q3wu","executionInfo":{"status":"ok","timestamp":1684948554965,"user_tz":-120,"elapsed":309,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}},"outputId":"1ca32c4a-b627-4206-c631-0d82dab0f5e1"},"execution_count":168,"outputs":[{"output_type":"stream","name":"stdout","text":["BLEU 1-gram score for GRU translations: 0.06544866793155198\n"]}]},{"cell_type":"markdown","source":["As expected after manually inspecting translations, custom GRU model does not perform well on more complex translations."],"metadata":{"id":"WDLxyamj0NIq"}},{"cell_type":"code","source":["individual_scores_mt5_wiki = np.zeros(translations_wiki_len)\n","candidates_mt5_wiki = [translation.split() for translation in translations_mt5_wiki]\n","\n","for i in range(translations_wiki_len):\n","    individual_scores_mt5_wiki[i] = sentence_bleu([reference_wiki[i]], candidates_mt5_wiki[i], weights=(1, 0, 0, 0))\n","\n","print(f\"BLEU 1-gram score for mT5 translations: {np.mean(individual_scores_mt5_wiki)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"in-eGszIrKL7","executionInfo":{"status":"ok","timestamp":1684948547112,"user_tz":-120,"elapsed":14,"user":{"displayName":"Jacek Spalinski","userId":"02340419711412381668"}},"outputId":"6ccc6a56-a619-4959-bfa0-e9301cb9aee3"},"execution_count":167,"outputs":[{"output_type":"stream","name":"stdout","text":["BLEU 1-gram score for mT5 translations: 0.723360264694758\n"]}]},{"cell_type":"markdown","source":["1-gram BLEU score is somehow suprisingly higher for mT5 model. However, with short sentences in initial dataset, we saw mT5 model produced correct translations that did not match \"ground truth\". Perhabs in longer wikipedia sentences this ambiguity is less present, therefore translations match closer \"ground truth\"."],"metadata":{"id":"ZKOUur5czHL-"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true,"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyMU1B9PbQUWShBNrYsrplD/"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}